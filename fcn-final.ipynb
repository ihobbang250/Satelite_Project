{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2023-07-09T15:40:43.839762Z","iopub.execute_input":"2023-07-09T15:40:43.840154Z","iopub.status.idle":"2023-07-09T15:40:56.442819Z","shell.execute_reply.started":"2023-07-09T15:40:43.840123Z","shell.execute_reply":"2023-07-09T15:40:56.441659Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport cv2\nimport pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision import models\nimport torch.optim as optim\nfrom torchsummary import summary as model_summary\n\nfrom tqdm import tqdm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-07-09T15:40:56.446281Z","iopub.execute_input":"2023-07-09T15:40:56.446619Z","iopub.status.idle":"2023-07-09T15:41:00.901329Z","shell.execute_reply.started":"2023-07-09T15:40:56.446571Z","shell.execute_reply":"2023-07-09T15:41:00.900338Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Utils","metadata":{}},{"cell_type":"code","source":"# RLE 디코딩 함수\ndef rle_decode(mask_rle, shape):\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)\n\n# RLE 인코딩 함수\ndef rle_encode(mask):\n    pixels = mask.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T15:41:00.903422Z","iopub.execute_input":"2023-07-09T15:41:00.904054Z","iopub.status.idle":"2023-07-09T15:41:00.913060Z","shell.execute_reply.started":"2023-07-09T15:41:00.904016Z","shell.execute_reply":"2023-07-09T15:41:00.912199Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Custom Dataset","metadata":{}},{"cell_type":"code","source":"class SatelliteDataset(Dataset):\n    def __init__(self, csv_file, image_dir, transform=None, infer=False):\n        self.data = pd.read_csv(csv_file)\n        self.image_dir = image_dir\n        self.transform = transform\n        self.infer = infer\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_filename = self.data.iloc[idx, 1].lstrip('.')\n        img_path = self.image_dir + img_filename\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.infer:\n            if self.transform:\n                image = self.transform(image=image)['image']\n            return image\n\n        mask_rle = self.data.iloc[idx, 2]\n        mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n\n        if self.transform:\n            augmented = self.transform(image=image, mask=mask)\n            image = augmented['image']\n            mask = augmented['mask']\n\n        return image, mask","metadata":{"execution":{"iopub.status.busy":"2023-07-09T15:41:00.916571Z","iopub.execute_input":"2023-07-09T15:41:00.917288Z","iopub.status.idle":"2023-07-09T15:41:00.928519Z","shell.execute_reply.started":"2023-07-09T15:41:00.917209Z","shell.execute_reply":"2023-07-09T15:41:00.927725Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### DataLoader","metadata":{}},{"cell_type":"code","source":"transform = A.Compose(\n    [   \n        A.Resize(224, 224),\n        A.Normalize(),\n        ToTensorV2()\n    ]\n)\n\ndataset = SatelliteDataset(csv_file='/kaggle/input/dacon-building-data/train.csv', image_dir='/kaggle/input/dacon-building-data', transform=transform)\ndataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T15:41:00.929683Z","iopub.execute_input":"2023-07-09T15:41:00.930813Z","iopub.status.idle":"2023-07-09T15:41:03.870797Z","shell.execute_reply.started":"2023-07-09T15:41:00.930780Z","shell.execute_reply":"2023-07-09T15:41:03.869853Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Build Model","metadata":{}},{"cell_type":"code","source":"class FCN8s(nn.Module):\n    def __init__(self, num_classes=1):\n        super(FCN8s, self).__init__()\n\n        ##### Build VGG #####\n        # 3x3 Conv 1 Block\n        self.conv1 = nn.Sequential(\n            # 1 Conv\n            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1), # 512\n            nn.ReLU(inplace=True),\n            # 2 Conv\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1), # 512\n            nn.ReLU(inplace=True),\n            # 3 Max Pooling\n            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True) # 256\n        )\n        # 3x3 Conv 2 Block\n        self.conv2 = nn.Sequential(\n            # 1 Conv\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1), # 256\n            nn.ReLU(inplace=True),\n            # 2 Conv\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1), # 256\n            nn.ReLU(inplace=True),\n            # 3 Max Pooling\n            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True) # 128\n        )\n        # 3x3 Conv 3 Block\n        self.conv3 = nn.Sequential(\n            # 1 Conv\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1), # 128\n            nn.ReLU(inplace=True),\n            # 2 Conv\n            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1), # 128\n            nn.ReLU(inplace=True),\n            # 3 Conv\n            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1), # 128\n            nn.ReLU(inplace=True),\n            # 4 Max Pooling\n            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True) # 64\n        )\n        # Score Pool 3 Block\n        self.score_3b = nn.Sequential(\n            nn.Conv2d(in_channels=256, out_channels=num_classes, kernel_size=1, stride=1, padding=0)\n        )        \n        # 3x3 Conv 4 Block\n        self.conv4 = nn.Sequential(\n            # 1 Conv\n            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1), # 64\n            nn.ReLU(inplace=True),\n            # 2 Conv\n            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1), # 64\n            nn.ReLU(inplace=True),\n            # 3 Conv\n            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1), # 64\n            nn.ReLU(inplace=True),\n            # 4 Max Pooling\n            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True) # 32\n        )\n        # Score Pool 4 Block\n        self.score_4b = nn.Sequential(\n            nn.Conv2d(in_channels=512, out_channels=num_classes, kernel_size=1, stride=1, padding=0)\n        )     \n        # 3x3 Conv 5 Block\n        self.conv5 = nn.Sequential(\n            # 1 Conv\n            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1), # 32\n            nn.ReLU(inplace=True),\n            # 2 Conv\n            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1), # 32\n            nn.ReLU(inplace=True),\n            # 3 Conv\n            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1), # 32\n            nn.ReLU(inplace=True),\n            # 4 Max Pooling\n            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True) # 16\n        )\n        ##### Build FCN ####\n\n        # 1x1 Conv 6 FC\n        self.fc6 = nn.Sequential(\n            nn.Conv2d(in_channels=512, out_channels=4096, kernel_size=1, stride=1, padding=0),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d()\n        )\n        # 1x1 Conv 7 FC\n        self.fc7 = nn.Sequential(\n            nn.Conv2d(in_channels=4096, out_channels=4096, kernel_size=1, stride=1, padding=0),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d()\n        )\n        # 1x1 Conv 8 FC (Score)\n        self.fc8 = nn.Conv2d(in_channels=4096, out_channels=num_classes, kernel_size=1, stride=1, padding=0)\n        \n        # Up Score\n        self.upscore = nn.ConvTranspose2d(in_channels=num_classes, out_channels=num_classes, kernel_size=4, stride=2, padding=1)\n        # Up Score Conv4\n        self.upscore_4b = nn.ConvTranspose2d(in_channels=num_classes, out_channels=num_classes, kernel_size=4, stride=2, padding=1)\n        # Up Score Conv3\n        self.upscore_3b = nn.ConvTranspose2d(in_channels=num_classes, out_channels=num_classes, kernel_size=16, stride=8, padding=4)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        \n        x = self.conv3(x)        \n        s3 = self.score_3b(x)\n        \n        x = self.conv4(x)\n        s4 = self.score_4b(x)\n        \n        x = self.conv5(x)\n        x = self.fc6(x)\n        x = self.fc7(x)\n        x = self.fc8(x)\n        \n        us = self.upscore(x)\n        sum_us_s4 = us + s4\n        \n        us4 = self.upscore_4b(sum_us_s4)\n        sum_us4_s3 = us4 + s3\n        \n        us3 = self.upscore_3b(sum_us4_s3)\n        \n        return us3\n    \n\nmodel = FCN8s()\nmodel_summary(model, input_size=(3, 256, 256), device='cpu')","metadata":{"execution":{"iopub.status.busy":"2023-07-09T15:41:03.872120Z","iopub.execute_input":"2023-07-09T15:41:03.872962Z","iopub.status.idle":"2023-07-09T15:41:05.339725Z","shell.execute_reply.started":"2023-07-09T15:41:03.872930Z","shell.execute_reply":"2023-07-09T15:41:05.338660Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 256, 256]           1,792\n              ReLU-2         [-1, 64, 256, 256]               0\n            Conv2d-3         [-1, 64, 256, 256]          36,928\n              ReLU-4         [-1, 64, 256, 256]               0\n         MaxPool2d-5         [-1, 64, 128, 128]               0\n            Conv2d-6        [-1, 128, 128, 128]          73,856\n              ReLU-7        [-1, 128, 128, 128]               0\n            Conv2d-8        [-1, 128, 128, 128]         147,584\n              ReLU-9        [-1, 128, 128, 128]               0\n        MaxPool2d-10          [-1, 128, 64, 64]               0\n           Conv2d-11          [-1, 256, 64, 64]         295,168\n             ReLU-12          [-1, 256, 64, 64]               0\n           Conv2d-13          [-1, 256, 64, 64]         590,080\n             ReLU-14          [-1, 256, 64, 64]               0\n           Conv2d-15          [-1, 256, 64, 64]         590,080\n             ReLU-16          [-1, 256, 64, 64]               0\n        MaxPool2d-17          [-1, 256, 32, 32]               0\n           Conv2d-18            [-1, 1, 32, 32]             257\n           Conv2d-19          [-1, 512, 32, 32]       1,180,160\n             ReLU-20          [-1, 512, 32, 32]               0\n           Conv2d-21          [-1, 512, 32, 32]       2,359,808\n             ReLU-22          [-1, 512, 32, 32]               0\n           Conv2d-23          [-1, 512, 32, 32]       2,359,808\n             ReLU-24          [-1, 512, 32, 32]               0\n        MaxPool2d-25          [-1, 512, 16, 16]               0\n           Conv2d-26            [-1, 1, 16, 16]             513\n           Conv2d-27          [-1, 512, 16, 16]       2,359,808\n             ReLU-28          [-1, 512, 16, 16]               0\n           Conv2d-29          [-1, 512, 16, 16]       2,359,808\n             ReLU-30          [-1, 512, 16, 16]               0\n           Conv2d-31          [-1, 512, 16, 16]       2,359,808\n             ReLU-32          [-1, 512, 16, 16]               0\n        MaxPool2d-33            [-1, 512, 8, 8]               0\n           Conv2d-34           [-1, 4096, 8, 8]       2,101,248\n             ReLU-35           [-1, 4096, 8, 8]               0\n        Dropout2d-36           [-1, 4096, 8, 8]               0\n           Conv2d-37           [-1, 4096, 8, 8]      16,781,312\n             ReLU-38           [-1, 4096, 8, 8]               0\n        Dropout2d-39           [-1, 4096, 8, 8]               0\n           Conv2d-40              [-1, 1, 8, 8]           4,097\n  ConvTranspose2d-41            [-1, 1, 16, 16]              17\n  ConvTranspose2d-42            [-1, 1, 32, 32]              17\n  ConvTranspose2d-43          [-1, 1, 256, 256]             257\n================================================================\nTotal params: 33,602,406\nTrainable params: 33,602,406\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.75\nForward/backward pass size (MB): 297.77\nParams size (MB): 128.18\nEstimated Total Size (MB): 426.70\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Train Model","metadata":{}},{"cell_type":"code","source":"# model 초기화\nmodel = FCN8s().to(device)\n# if torch.cuda.device_count() == 2:\n#     _net = FCN8s().cuda()\n#     model = nn.DataParallel(_net).to(device)\n\n# loss function과 optimizer 정의\ncriterion = torch.nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n# training loop\nbest_loss = float('inf')  # 초기 최소 손실값을 무한대로 설정\npatience = 3  # 손실이 감소하지 않더라도 몇 번까지 기다릴지 지정\nnum_bad_epochs = 0  # 기다리는 동안 손실이 감소하지 않은 에폭 수\n\nfor epoch in range(10):  # 10 에폭 동안 학습합니다.\n    model.train()\n    epoch_loss = 0\n    for images, masks in tqdm(dataloader):\n        images = images.float().to(device)\n        masks = masks.float().to(device)\n\n        optimizer.zero_grad()\n        # Forward pass\n        outputs = model(images)\n        \n        # Compute loss\n        loss = criterion(outputs, masks.unsqueeze(1))\n        \n        # Backward pass\n        loss.backward()\n        \n        # Update weights\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n    avg_loss = epoch_loss / len(dataloader)\n    print(f'Epoch {epoch+1}, Loss: {avg_loss}')\n    \n    # Early stopping check\n    if avg_loss < best_loss:\n        best_loss = avg_loss\n        num_bad_epochs = 0\n    else:\n        num_bad_epochs += 1\n        if num_bad_epochs >= patience:\n            print('Early stopping triggered. Training stopped.')\n            break","metadata":{"execution":{"iopub.status.busy":"2023-07-09T15:41:05.341021Z","iopub.execute_input":"2023-07-09T15:41:05.341944Z","iopub.status.idle":"2023-07-09T16:20:27.400004Z","shell.execute_reply.started":"2023-07-09T15:41:05.341912Z","shell.execute_reply":"2023-07-09T16:20:27.398881Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 447/447 [04:09<00:00,  1.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.22316076051468817\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 447/447 [03:46<00:00,  1.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.13991661446473208\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 447/447 [03:54<00:00,  1.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.1268857919196421\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 447/447 [03:53<00:00,  1.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 0.1205821404154402\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 447/447 [03:57<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 0.11473511367769583\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 447/447 [03:58<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Loss: 0.11156692125853276\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 447/447 [03:55<00:00,  1.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7, Loss: 0.10806163453749096\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 447/447 [03:56<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8, Loss: 0.10592983003864086\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 447/447 [03:53<00:00,  1.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9, Loss: 0.10364015119554479\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 447/447 [03:53<00:00,  1.92it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 10, Loss: 0.10205700956868378\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Save & Load Model","metadata":{}},{"cell_type":"code","source":"#Save the model\nsave_path = '/kaggle/working/model.pth'\ntorch.save(model.state_dict(), save_path)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T16:20:47.246103Z","iopub.execute_input":"2023-07-09T16:20:47.246473Z","iopub.status.idle":"2023-07-09T16:20:47.510540Z","shell.execute_reply.started":"2023-07-09T16:20:47.246443Z","shell.execute_reply":"2023-07-09T16:20:47.509541Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Load the model\n# model = FCN8s()\n# model.load_state_dict(torch.load('/kaggle/input/trained-model/' + 'model.pth'))","metadata":{"execution":{"iopub.status.busy":"2023-07-09T16:20:27.429736Z","iopub.status.idle":"2023-07-09T16:20:27.430542Z","shell.execute_reply.started":"2023-07-09T16:20:27.430247Z","shell.execute_reply":"2023-07-09T16:20:27.430271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference","metadata":{}},{"cell_type":"code","source":"test_dataset = SatelliteDataset(csv_file='/kaggle/input/dacon-building-data/test.csv', image_dir='/kaggle/input/dacon-building-data', transform=transform, infer=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T16:20:58.781579Z","iopub.execute_input":"2023-07-09T16:20:58.782320Z","iopub.status.idle":"2023-07-09T16:20:58.896161Z","shell.execute_reply.started":"2023-07-09T16:20:58.782270Z","shell.execute_reply":"2023-07-09T16:20:58.894959Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    model.eval()\n    result = []\n    for images in tqdm(test_dataloader):\n        images = images.float().to(device)\n        \n        outputs = model(images)\n        masks = torch.sigmoid(outputs).cpu().numpy()\n        masks = np.squeeze(masks, axis=1)\n        masks = (masks > 0.35).astype(np.uint8) # Threshold = 0.35\n        \n        for i in range(len(images)):\n            mask_rle = rle_encode(masks[i])\n            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n                result.append(-1)\n            else:\n                result.append(mask_rle)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T16:21:06.645725Z","iopub.execute_input":"2023-07-09T16:21:06.646103Z","iopub.status.idle":"2023-07-09T16:27:32.373566Z","shell.execute_reply.started":"2023-07-09T16:21:06.646074Z","shell.execute_reply":"2023-07-09T16:27:32.372273Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"100%|██████████| 3790/3790 [06:25<00:00,  9.83it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"submit = pd.read_csv('/kaggle/input/dacon-building-data/sample_submission.csv')\nsubmit['mask_rle'] = result","metadata":{"execution":{"iopub.status.busy":"2023-07-09T16:29:20.504168Z","iopub.execute_input":"2023-07-09T16:29:20.504630Z","iopub.status.idle":"2023-07-09T16:29:20.574256Z","shell.execute_reply.started":"2023-07-09T16:29:20.504572Z","shell.execute_reply":"2023-07-09T16:29:20.572973Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"submit.to_csv('./submit.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T16:29:23.122177Z","iopub.execute_input":"2023-07-09T16:29:23.122546Z","iopub.status.idle":"2023-07-09T16:29:24.898600Z","shell.execute_reply.started":"2023-07-09T16:29:23.122515Z","shell.execute_reply":"2023-07-09T16:29:24.897607Z"},"trusted":true},"execution_count":13,"outputs":[]}]}